{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7BxRdy9M5DIu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential, Model, losses, optimizers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense,BatchNormalization,LeakyReLU,Conv2DTranspose,Conv2D,Dropout,Flatten, Reshape\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "import pickle\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "NOISE_DIM = 100\n",
        "BATCH_SIZE = 25\n",
        "INSTANCE_NUM = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UjAr7Ejp5h7v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8192)              819200    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 8192)             32768     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 8192)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 8, 8, 256)         524288    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 8, 8, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 256)      1048576   \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      1048576   \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 32, 32, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 128)      524288    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 128, 128, 64)     131072    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 128, 128, 1)       1024      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,132,864\n",
            "Trainable params: 4,114,944\n",
            "Non-trainable params: 17,920\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer HeUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def generator_model(noise_dim):\n",
        "    model = Sequential()\n",
        "    initializer = tf.keras.initializers.HeUniform()\n",
        "    # I use Layer Normalization because my batch size is small due to small vRAM\n",
        "    model.add(Dense(8*8*128, use_bias=False, input_shape=(noise_dim,), kernel_initializer=initializer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Reshape((8, 8, 128)))\n",
        "    \n",
        "    model.add(Conv2D(256, 4, strides=1, padding='same', use_bias=False, kernel_initializer=initializer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    model.add(Conv2DTranspose(256, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    model.add(Conv2DTranspose(256, 4, strides=2, padding='same', use_bias=False, kernel_initializer=initializer))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    \n",
        "    # Read that removing normalization in the last couple of layers makes the output less smooth and less constraint\n",
        "    model.add(Conv2DTranspose(128, 4, strides=2, padding='same', use_bias=False, activation='leaky_relu', kernel_initializer=initializer))\n",
        "\n",
        "    model.add(Conv2DTranspose(64, 4, strides=2, padding='same', use_bias=False, activation='leaky_relu', kernel_initializer=initializer))\n",
        "\n",
        "    model.add(Conv2D(1, 4, strides=1, padding='same', use_bias=False, activation='tanh', kernel_initializer=initializer))\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = generator_model(NOISE_DIM)\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xBowmbrC7sgk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 1)]     0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 43, 43, 128)       1280      \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 43, 43, 128)       0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 43, 43, 128)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 15, 15, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 5, 5, 256)         295168    \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 2, 2, 128)         295040    \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 886,785\n",
            "Trainable params: 886,785\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def discriminator_model():\n",
        "\n",
        "    input_layer = Input(shape=[128, 128, 1])\n",
        "\n",
        "    conv1 = Conv2D(128, 3, strides=3, padding='same')(input_layer)\n",
        "    act1 = LeakyReLU()(conv1)\n",
        "    drop1 = Dropout(0.3)(act1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, strides=3, padding='same')(drop1)\n",
        "    act2 = LeakyReLU()(conv2)\n",
        "    drop2 = Dropout(0.3)(act2)\n",
        "\n",
        "\n",
        "    conv3 = Conv2D(256, 3, strides=3, padding='same')(drop2)\n",
        "    act3 = LeakyReLU()(conv3)\n",
        "    drop3 = Dropout(0.3)(act3)\n",
        "\n",
        "\n",
        "    conv4 = Conv2D(128, 3, strides=3, padding='same')(drop3)\n",
        "    act4 = LeakyReLU()(conv4)\n",
        "    drop4 = Dropout(0.3)(act4)\n",
        "\n",
        "\n",
        "    conv5 = Conv2D(128, 3, strides=3, padding='same')(drop4)\n",
        "    act5 = LeakyReLU()(conv5)\n",
        "    drop5 = Dropout(0.3)(act5)\n",
        "\n",
        "\n",
        "    flat = Flatten()(drop5)\n",
        "    output = Dense(1)(flat)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "    return model\n",
        "discriminator = discriminator_model()\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-WWGt2kh7n9",
        "outputId": "54a90858-8c21-4608-c201-8aadd102f07f"
      },
      "outputs": [],
      "source": [
        "with open(\"data.pkl\", \"rb\") as file:\n",
        "    df = pickle.load(file)[:INSTANCE_NUM]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkRUTTv1-oCA",
        "outputId": "19c10756-22ab-484c-e162-d12a501d7042"
      },
      "outputs": [],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(np.asarray(df, dtype = np.float16).reshape(-1, 128, 128,1))\n",
        "del df\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "def plot_image(image,epoch,batch_number):\n",
        "    img = cv2.resize(np.array(image),(512,512))\n",
        "    cv2.imshow(f\"output_show\",img)\n",
        "    if batch_number == 10000//BATCH_SIZE:\n",
        "        cv2.imwrite(f\"model_3/{epoch}.jpg\", (img * 254).astype(np.uint8))\n",
        "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "        return\n",
        "    \n",
        "def plot_losses(epoch):\n",
        "    fig, ax1 = plt.subplots(figsize=(6, 3))\n",
        "    ax1.plot(gen_losses,label=\"generator\")\n",
        "    ax1.plot(dis_losses,label=\"discriminator\")\n",
        "    ax1.legend()\n",
        "    ax1.set_yscale('log')\n",
        "    ax1.set_ylim(.1, 3)\n",
        "    ax1.set_title(\"Losses\")\n",
        "    ax1.set_xlabel(\"epoch\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.set_xticks(range(0, epoch, 5)) \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ProgressBarBatch(batch_number,mag):\n",
        "    total = INSTANCE_NUM//BATCH_SIZE\n",
        "    print(\"Batch Progress:\",\"\\t\\t\",\n",
        "          (u\"■\"*(batch_number*mag//total)),\n",
        "          u\"□\"*((total-batch_number)*mag//total),\n",
        "          \"\\t\",\n",
        "          batch_number,\"/\",total, sep='')\n",
        "    \n",
        "def ProgressBarEpoch(epoch,epochs,mag):\n",
        "    print(\"Epoch Progress:\",\"\\t\\t\",\n",
        "          (u\"■\"*(epoch*mag//epochs)),\n",
        "          u\"□\"*((epochs-epoch)*mag//epochs),\n",
        "          \"\\t\",epoch + 1,\"/\",epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_func = losses.BinaryCrossentropy(from_logits=True)\n",
        "def gen_loss_calc(fake):\n",
        "    return loss_func(tf.ones_like(fake), fake)\n",
        "\n",
        "def dis_loss_calc(real, fake):\n",
        "    real_loss = loss_func(tf.ones_like(real), real)\n",
        "    fake_loss = loss_func(tf.zeros_like(fake), fake)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def classify_as_real(fake_or_real_output):\n",
        "    threshold = 0.5  \n",
        "    classified_as_real = tf.greater(fake_or_real_output, threshold)\n",
        "    return tf.reduce_sum(tf.cast(classified_as_real, tf.int32))\n",
        "\n",
        "gen_opt= optimizers.Adam(\n",
        "    learning_rate=1e-5,\n",
        "    )\n",
        "dis_opt = optimizers.Adam(\n",
        "    learning_rate=1e-5,\n",
        "    )\n",
        "\n",
        "gen_losses = []\n",
        "dis_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(images, batch_size, noise_dim,epoch,batch_number,epochs):\n",
        "    if len(images) < batch_size:\n",
        "        print(f\"Warning: Not enough images for a full batch. Using {len(images)} images.\")\n",
        "        batch_size = len(images)\n",
        "    start = time.time()\n",
        "    noise = tf.random.normal([batch_size, noise_dim],stddev = 0.3)\n",
        "\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated = generator(noise, training=True)\n",
        "\n",
        "        real = discriminator(images, training=True)\n",
        "        fake = discriminator(generated, training=True)\n",
        "\n",
        "        gen_loss = gen_loss_calc(fake)\n",
        "        dis_loss = dis_loss_calc(real, fake)\n",
        "        \n",
        "        \n",
        "        gen_losses.append(gen_loss.numpy())\n",
        "        dis_losses.append(dis_loss.numpy())\n",
        "        \n",
        "        gen_train_started = False\n",
        "        if dis_loss<gen_loss*1.25 or gen_train_started==True:\n",
        "            display(\"Generator is training\")\n",
        "            gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "            gen_opt.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "            gen_train_started = True\n",
        "            \n",
        "        dis_gradients = disc_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
        "        dis_opt.apply_gradients(zip(dis_gradients, discriminator.trainable_variables))\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        ProgressBarEpoch(epoch,epochs,20)\n",
        "        ProgressBarBatch(batch_number,20)\n",
        "        display(f\"gen_loss: {gen_loss:.4f}\")\n",
        "        display(f\"disc_loss: {dis_loss:.4f}\")\n",
        "        display(f\"time: {time.time() - start:.2f}s\") \n",
        "        \n",
        "        if batch_number % 20 == 0:\n",
        "            plot_image(generated[0],epoch,batch_number)     \n",
        "        if batch_number == INSTANCE_NUM//BATCH_SIZE:\n",
        "            generator.save(\"generator.keras\")\n",
        "            discriminator.save(\"discriminator.keras\")\n",
        "    \n",
        "\n",
        "def train(dataset, epochs= 20,batch_size=32):\n",
        "    start = time.time()\n",
        "    for epoch_number in range(epochs):\n",
        "        batch_number = 1\n",
        "        for batch in dataset:\n",
        "            batch_number+=1\n",
        "            train_epoch(images = batch,\n",
        "                        batch_size = batch_size,\n",
        "                        noise_dim=NOISE_DIM,\n",
        "                        epoch=epoch_number,\n",
        "                        batch_number=batch_number,\n",
        "                        epochs = epochs)\n",
        "            display(f\"Total time: {time.time() - start:.2f}s\")\n",
        "        pd.DataFrame({\"gen\":gen_losses,\"dis\":dis_losses}).to_csv(\"losses.csv\")\n",
        "        plot_losses(epoch_number)\n",
        "        time.sleep(4)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jvx-MxLny_yH",
        "outputId": "980360e5-7127-4165-9aad-a34dfbd630cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch Progress: \t  □□□□□□□□□□□□□□□□□□□□ \t 0.01\n",
            "Batch Progress:\t□□□□□□□□□□□□□□□□□□□\t2/400\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'gen_loss: 0.6874'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'disc_loss: 1.9236'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'time: 4.85s'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'Total time: 5.23s'"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "{{function_node __wrapped__Conv2DBackpropInput_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[25,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2DBackpropInput]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[11], line 53\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs, batch_size)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m     52\u001b[0m     batch_number\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 53\u001b[0m     \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnoise_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNOISE_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbatch_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     display(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     60\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgen\u001b[39m\u001b[38;5;124m\"\u001b[39m:gen_losses,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdis\u001b[39m\u001b[38;5;124m\"\u001b[39m:dis_losses})\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[11], line 29\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(images, batch_size, noise_dim, epoch, batch_number, epochs)\u001b[0m\n\u001b[0;32m     26\u001b[0m     gen_opt\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gen_gradients, generator\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[0;32m     27\u001b[0m     gen_train_started \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m dis_gradients \u001b[38;5;241m=\u001b[39m \u001b[43mdisc_tape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdis_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m dis_opt\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(dis_gradients, discriminator\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[0;32m     32\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
            "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
            "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py:581\u001b[0m, in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    572\u001b[0m shape_0, shape_1 \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape_n([op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# functions for performance reasons in Eager mode. gen_nn_ops functions take a\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` parameter, but nn_ops functions do not. So if we were\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;66;03m# to use the nn_ops functions, we would have to convert `padding` and\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;66;03m# `explicit_paddings` into a single `padding` parameter, increasing overhead\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;66;03m# in Eager mode.\u001b[39;00m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 581\u001b[0m     \u001b[43mgen_nn_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d_backprop_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape_0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdilations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdilations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexplicit_paddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplicit_paddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cudnn_on_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    591\u001b[0m     gen_nn_ops\u001b[38;5;241m.\u001b[39mconv2d_backprop_filter(\n\u001b[0;32m    592\u001b[0m         op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    593\u001b[0m         shape_1,\n\u001b[0;32m    594\u001b[0m         grad,\n\u001b[0;32m    595\u001b[0m         dilations\u001b[38;5;241m=\u001b[39mdilations,\n\u001b[0;32m    596\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[0;32m    597\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m    598\u001b[0m         explicit_paddings\u001b[38;5;241m=\u001b[39mexplicit_paddings,\n\u001b[0;32m    599\u001b[0m         use_cudnn_on_gpu\u001b[38;5;241m=\u001b[39muse_cudnn_on_gpu,\n\u001b[0;32m    600\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format)\n\u001b[0;32m    601\u001b[0m ]\n",
            "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py:1422\u001b[0m, in \u001b[0;36mconv2d_backprop_input\u001b[1;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1420\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1422\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   1424\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Conv2DBackpropInput_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[25,128,128,64] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Conv2DBackpropInput]"
          ]
        }
      ],
      "source": [
        "train(dataset, 100, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
