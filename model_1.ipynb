{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7BxRdy9M5DIu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential, Model, backend, losses, optimizers\n",
        "from tensorflow import ones_like, zeros_like, random, GradientTape\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense,BatchNormalization,LeakyReLU,Conv2DTranspose,Conv2D,Dropout,Flatten, Reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UjAr7Ejp5h7v"
      },
      "outputs": [],
      "source": [
        "def generator_model(noise_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8*8*512, use_bias=False, input_shape=(noise_dim,)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Reshape((8, 8, 512)))\n",
        "\n",
        "    model.add(Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "\n",
        "    model.add(Conv2DTranspose(1, (4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "id": "HlxaafKRKZsG",
        "outputId": "1e6bc18c-0d64-4d55-e8bb-2064c3923cdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 32768)             3276800   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32768)            131072    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 32768)             0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 16, 16, 256)      2097152   \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 128)      524288    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 32, 32, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 64)       131072    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 64, 64, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 128, 128, 1)      1024      \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,163,200\n",
            "Trainable params: 6,096,768\n",
            "Non-trainable params: 66,432\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "generator = generator_model(100)\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xBowmbrC7sgk"
      },
      "outputs": [],
      "source": [
        "def discriminator_model():\n",
        "\n",
        "    input_layer = Input(shape=[128, 128, 3])\n",
        "\n",
        "    conv1 = Conv2D(16, (3, 3), strides=(3,3), padding='same')(input_layer)\n",
        "    act1 = LeakyReLU()(conv1)\n",
        "    drop1 = Dropout(0.3)(act1)\n",
        "\n",
        "    conv2 = Conv2D(32, (3, 3), strides=(3,3), padding='same')(drop1)\n",
        "    act2 = LeakyReLU()(conv2)\n",
        "    drop2 = Dropout(0.3)(act2)\n",
        "\n",
        "\n",
        "    conv3 = Conv2D(64, (3, 3), strides=(3,3), padding='same')(drop2)\n",
        "    act3 = LeakyReLU()(conv3)\n",
        "    drop3 = Dropout(0.3)(act3)\n",
        "\n",
        "\n",
        "    conv4 = Conv2D(128, (3, 3), strides=(3,3), padding='same')(drop3)\n",
        "    act4 = LeakyReLU()(conv4)\n",
        "    drop4 = Dropout(0.3)(act4)\n",
        "\n",
        "\n",
        "    conv5 = Conv2D(128, (3, 3), strides=(3,3), padding='same')(drop4)\n",
        "    act5 = LeakyReLU()(conv5)\n",
        "    drop5 = Dropout(0.3)(act5)\n",
        "\n",
        "\n",
        "    flat = Flatten()(drop5)\n",
        "    output = Dense(1)(flat)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "udAzOLe1Q7g3",
        "outputId": "70145b4c-4843-45fc-bee4-01cdd9fad4cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 43, 43, 16)        448       \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 43, 43, 16)        0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 43, 43, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 15, 15, 32)        4640      \n",
            "                                                                 \n",
            " leaky_re_lu_5 (LeakyReLU)   (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 5, 5, 64)          18496     \n",
            "                                                                 \n",
            " leaky_re_lu_6 (LeakyReLU)   (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 2, 2, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_7 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 1, 1, 128)         147584    \n",
            "                                                                 \n",
            " leaky_re_lu_8 (LeakyReLU)   (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 245,153\n",
            "Trainable params: 245,153\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "discriminator = discriminator_model()\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kYS7PZJRY3kI"
      },
      "outputs": [],
      "source": [
        "loss_func = losses.BinaryCrossentropy(from_logits=True)\n",
        "def gen_loss_calc(fake):\n",
        "    return loss_func(ones_like(fake), fake)\n",
        "\n",
        "def dis_loss_calc(real, fake):\n",
        "    real_loss = loss_func(ones_like(real), real)\n",
        "    fake_loss = loss_func(zeros_like(fake), fake)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n5RKp7S5Q_ny"
      },
      "outputs": [],
      "source": [
        "gen_opt = optimizers.Adam(1e-4)\n",
        "dis_opt = optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BjsZfm1RhlFt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib qt\n",
        "plt.ion()\n",
        "def plot_image(image):\n",
        "    # Assuming the image is in the range [0,1] or [-1,1]\n",
        "    image = (image + 1) / 2  # Rescale image to [0,1] if needed\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Turn off axis for a cleaner display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vA1YMuoiepzl"
      },
      "outputs": [],
      "source": [
        "def train_epoch(images, batch_size, noise_dim,epoch,batch_number):\n",
        "    if len(images) < batch_size:\n",
        "        print(f\"Warning: Not enough images for a full batch. Using {len(images)} images.\")\n",
        "        batch_size = len(images)\n",
        "    start = time.time()\n",
        "    noise = random.normal([batch_size, noise_dim])\n",
        "\n",
        "    global fig, ax\n",
        "\n",
        "    with GradientTape() as gen_tape, GradientTape() as disc_tape:\n",
        "        generated = generator(noise, training=True)\n",
        "        plot_image(images[0])\n",
        "        #print(generated.shape,images.shape)\n",
        "        real = discriminator(images, training=True)\n",
        "        fake = discriminator(generated, training=True)\n",
        "\n",
        "        gen_loss = gen_loss_calc(fake)\n",
        "        dis_loss = dis_loss_calc(real, fake)\n",
        "\n",
        "        real_acc = np.mean(real > 0.5)\n",
        "        fake_acc = np.mean(fake < 0.5)\n",
        "        disc_acc = 0.5 * (real_acc + fake_acc)\n",
        "        gen_acc = np.mean(fake > 0.5)\n",
        "\n",
        "        gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        dis_gradients = disc_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
        "\n",
        "        gen_opt.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "        dis_opt.apply_gradients(zip(dis_gradients, discriminator.trainable_variables))\n",
        "        clear_output(wait=True)\n",
        "        display(f\"Epoch {epoch + 1}/50 batch {batch_number}\")\n",
        "        display(f\"gen_loss: {gen_loss:.4f}, gen_acc: {gen_acc:.4f}\")\n",
        "        display(f\"disc_loss: {dis_loss:.4f}, disc_acc: {disc_acc:.4f}\")\n",
        "        display(f\"time: {time.time() - start:.2f}s\")    \n",
        "        if batch_number % 20 == 0:\n",
        "            plt.figure(figsize=(5, 5))\n",
        "            plot_image(generated[0])\n",
        "            plt.savefig(f'{epoch}_{batch_number}.png')\n",
        "            plt.show()\n",
        "            time.sleep(4)\n",
        "        if batch_number == 141:\n",
        "            generator.save(\"generator.keras\")\n",
        "            discriminator.save(\"discriminator.keras\")\n",
        "\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        k = 1\n",
        "        for batch in dataset:\n",
        "            print()\n",
        "            k+=1\n",
        "            train_epoch(batch,32,100,epoch,k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "i = 0\n",
        "def preprocess_image(img):\n",
        "    global i\n",
        "    img = Image.open(io.BytesIO(img[\"bytes\"]))\n",
        "    img = img.resize((128, 128))\n",
        "    img = img.convert(\"L\")\n",
        "    img = np.asarray(img, dtype=np.float16)\n",
        "    img_array = img/255\n",
        "    i+=1\n",
        "    print(f\"\\r{i}/{len(df)}                      \",end = '')\n",
        "    return img_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-WWGt2kh7n9",
        "outputId": "54a90858-8c21-4608-c201-8aadd102f07f"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_parquet(\"hf://datasets/Wejh/celeb-a-hq___0-to-4999___FLUX.1-dev_training_faces/base_transforms/train-00000-of-00001.parquet\")[[\"image\"]]\n",
        "\n",
        "# with open(\"data.pkl\", \"wb\") as file:\n",
        "#     # Use pickle.dump() to serialize the object\n",
        "#     pickle.dump(df, file)\n",
        "\n",
        "with open(\"data.pkl\", \"rb\") as file:\n",
        "    # Use pickle.load() to deserialize the object\n",
        "    df = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkRUTTv1-oCA",
        "outputId": "19c10756-22ab-484c-e162-d12a501d7042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8924/4462                      "
          ]
        }
      ],
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(np.array(df['image'].apply(preprocess_image).tolist(), dtype=np.float16).reshape(-1, 128, 128,1))\n",
        "del df\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jvx-MxLny_yH",
        "outputId": "980360e5-7127-4165-9aad-a34dfbd630cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"model\" \"                 f\"(type Functional).\n\nInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (32, 128, 128, 1)\n\nCall arguments received by layer \"model\" \"                 f\"(type Functional):\n  • inputs=tf.Tensor(shape=(32, 128, 128, 1), dtype=float16)\n  • training=True\n  • mask=None",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[25], line 52\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     51\u001b[0m k\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[25], line 14\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(images, batch_size, noise_dim, epoch, batch_number)\u001b[0m\n\u001b[0;32m     12\u001b[0m plot_image(images[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#print(generated.shape,images.shape)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m fake \u001b[38;5;241m=\u001b[39m discriminator(generated, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m gen_loss_calc(fake)\n",
            "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32md:\\program_files\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\input_spec.py:277\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    272\u001b[0m             value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape_as_list[\u001b[38;5;28mint\u001b[39m(axis)] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    274\u001b[0m             value,\n\u001b[0;32m    275\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m         }:\n\u001b[1;32m--> 277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    278\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    279\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: expected axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof input shape to have value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received input with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m             )\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Check shape.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m shape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"model\" \"                 f\"(type Functional).\n\nInput 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (32, 128, 128, 1)\n\nCall arguments received by layer \"model\" \"                 f\"(type Functional):\n  • inputs=tf.Tensor(shape=(32, 128, 128, 1), dtype=float16)\n  • training=True\n  • mask=None"
          ]
        }
      ],
      "source": [
        "train(dataset, 150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
